{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The Dataset contains the following 12 features:\n",
    "\n",
    "CustomerID: A unique identifier\n",
    "\n",
    "Age: The age of the customer\n",
    "\n",
    "Gender: The gender of the customer\n",
    "\n",
    "Tenure: The number of months the customer has stayed with the company\n",
    "\n",
    "Usage Frequency: The number of times the customer has used the service the past month\n",
    "\n",
    "Support calls: The number of support calls the customer has made the past month\n",
    "\n",
    "Payment Delay: Number of days the customer has delayed payment the past month\n",
    "\n",
    "Subscription Type: The type of subscription the customer has\n",
    "\n",
    "Contract Length: Duration of the contract\n",
    "\n",
    "Total Spend: The total amount the customer has spent\n",
    "\n",
    "Last Interaction: Number of days since the last interaction the customer has had with the company\n",
    "\n",
    "Churn: Whether the customer has churned or not"
   ],
   "id": "d3c9b23fdc4593fe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import packages",
   "id": "e9f1fd3a1455e495"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import winsound\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cleanup",
   "id": "75fa76e4f3a12269"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_set_dirty = pd.read_csv(\"Datasets/In/customer_churn_dataset-testing-master.csv\", sep=\",\")\n",
    "training_set_dirty = pd.read_csv(\"Datasets/In/customer_churn_dataset-training-master.csv\", sep=\",\")\n",
    "\n",
    "combined_set_dirty = pd.concat([training_set_dirty, test_set_dirty], ignore_index=True)\n",
    "combined_set_dirty = combined_set_dirty.drop(combined_set_dirty.columns[0], axis=1)"
   ],
   "id": "e5996c1307912019",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "missing_values = combined_set_dirty.isnull().sum()\n",
    "missing_values"
   ],
   "id": "91d0024f69a2ed3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "combined_set_dirty[combined_set_dirty.isna().any(axis=1)]",
   "id": "4882bbf13bf27dc5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "combined_set_dirty.dropna(inplace=True)\n",
    "\n",
    "combined_set_dirty.columns = [col.lower().replace(\" \", \"_\") for col in combined_set_dirty.columns]\n",
    "combined_set_dirty.info()"
   ],
   "id": "2e324d463036d0fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "combined_set_dirty[combined_set_dirty.isna().any(axis=1)]",
   "id": "146cafb599a48535",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "numerals = [\"age\", \"tenure\", \"usage_frequency\", \"support_calls\", \"payment_delay\", \"last_interaction\", \"churn\"]\n",
    "\n",
    "for col in numerals:\n",
    "    combined_set_dirty[col] = combined_set_dirty[col].astype(int)"
   ],
   "id": "8e09ae028a92a23c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cleaned_set = combined_set_dirty.copy()",
   "id": "99df682984f2c3ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Descriptive Analytics",
   "id": "8cb6551b19acf57f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Summary statistics\n",
    "print(\"Summary Statistics for Churned Customers:\")\n",
    "print(cleaned_set[cleaned_set['churn'] == 1].describe())\n",
    "print(\"\\nSummary Statistics for Non-Churned Customers:\")\n",
    "print(cleaned_set[cleaned_set['churn'] == 0].describe())\n",
    "\n",
    "# Correlation analysis\n",
    "correlation = cleaned_set.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation, annot=True, cmap='crest')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Churn rate\n",
    "churn_rate = cleaned_set['churn'].mean() * 100\n",
    "print(f\"Churn Rate: {churn_rate}%\")"
   ],
   "id": "600c63f799c47fc6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "numeric_cols = [\"age\", \"tenure\", \"usage_frequency\", \"support_calls\", \"payment_delay\", \"last_interaction\", \"total_spend\"]\n",
    "\n",
    "num_bins = 3\n",
    "\n",
    "excourse_set = cleaned_set.copy()\n",
    "\n",
    "for col in numeric_cols:\n",
    "    excourse_set[col] = pd.cut(cleaned_set[col], num_bins, duplicates='drop')\n",
    "    print(col)\n",
    "    for interval in excourse_set[col].cat.categories:\n",
    "        print(interval)"
   ],
   "id": "b537b572424af260",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "columns = [\"age\", \"gender\", \"tenure\", \"usage_frequency\", \"support_calls\", \"payment_delay\", \"subscription_type\",\n",
    "           \"contract_length\", \"total_spend\", \"last_interaction\"]\n",
    "\n",
    "stacked_data_percent = {}\n",
    "\n",
    "for col in columns:\n",
    "    category_counts = excourse_set.groupby([col, \"churn\"]).size().unstack(fill_value=0)\n",
    "\n",
    "    category_percent = category_counts.div(category_counts.sum(axis=1), axis=0) * 100\n",
    "    print(category_percent)\n",
    "    stacked_data_percent[col] = category_percent"
   ],
   "id": "8ef300b3fd2b569f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate the overall churn rate\n",
    "overall_churn_rate = excourse_set['churn'].mean() * 100\n",
    "\n",
    "# Add a new row to each DataFrame in stacked_data_percent with the overall churn rate\n",
    "for col, df in stacked_data_percent.items():\n",
    "    df.loc['Overall'] = [100 - overall_churn_rate, overall_churn_rate]\n",
    "\n",
    "colors = {0: 'green', 1: 'red'}\n",
    "for col, df in stacked_data_percent.items():\n",
    "    ax = df.plot(kind='barh', stacked=True, color=[colors[churn] for churn in df.columns],\n",
    "                 title=f'Percentage Chart of Churned Customers in {col}')\n",
    "    plt.ylabel(col)\n",
    "    plt.xlabel('Percentage')\n",
    "    plt.legend([\"No Churn\", \"Churn\"], loc='best')\n",
    "\n",
    "    # Add the percentage values on each bar\n",
    "    for p in ax.patches:\n",
    "        width = p.get_width()\n",
    "        height = p.get_height()\n",
    "        x, y = p.get_xy()\n",
    "        ax.text(x + width / 2,\n",
    "                y + height / 2,\n",
    "                '{:.1f} %'.format(width),\n",
    "                horizontalalignment='center',\n",
    "                verticalalignment='center')\n",
    "    plt.show()"
   ],
   "id": "c1d8fe6b690f4aeb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "combinations = list(itertools.combinations(columns, 2))\n",
    "\n",
    "# Analyze each combination\n",
    "for combination in combinations:\n",
    "    # Create a multi-index DataFrame\n",
    "    multi_index_df = excourse_set.set_index(list(combination) + ['churn'])\n",
    "\n",
    "    # Calculate the size of each group\n",
    "    grouped_df = multi_index_df.groupby(list(combination) + ['churn']).size()\n",
    "\n",
    "    # Unstack the DataFrame to get a cross-tabulation\n",
    "    cross_tab = grouped_df.unstack(fill_value=0)\n",
    "\n",
    "    # Convert absolute numbers to relative percentages\n",
    "    cross_tab_percent = cross_tab.div(cross_tab.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    # Print the cross-tabulation\n",
    "    print(f\"Cross-tabulation for {combination}:\")\n",
    "    print(cross_tab_percent)\n",
    "    print(\"\\n\")"
   ],
   "id": "5d07f1fc26972f59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "combinations = list(itertools.combinations(columns, 3))\n",
    "\n",
    "# Analyze each combination\n",
    "for combination in combinations:\n",
    "    # Create a multi-index DataFrame\n",
    "    multi_index_df = excourse_set.set_index(list(combination) + ['churn'])\n",
    "\n",
    "    # Calculate the size of each group\n",
    "    grouped_df = multi_index_df.groupby(list(combination) + ['churn']).size()\n",
    "\n",
    "    # Unstack the DataFrame to get a cross-tabulation\n",
    "    cross_tab = grouped_df.unstack(fill_value=0)\n",
    "\n",
    "    # Convert absolute numbers to relative percentages\n",
    "    cross_tab_percent = cross_tab.div(cross_tab.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    # Print the cross-tabulation\n",
    "    print(f\"Cross-tabulation for {combination}:\")\n",
    "    print(cross_tab_percent)\n",
    "    print(\"\\n\") "
   ],
   "id": "632b7fadd84693fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Predictive Analytics",
   "id": "e6cee302e9512fdd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prepared_set = cleaned_set.copy()\n",
    "\n",
    "# Create a OneHotEncoder instance\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = ['gender', 'subscription_type', 'contract_length']\n",
    "\n",
    "# Fit and transform the data, converting it into a DataFrame\n",
    "prepared_set_encoded = pd.DataFrame(encoder.fit_transform(prepared_set[categorical_cols]))\n",
    "\n",
    "# Get feature names from the encoder and assign them as column names\n",
    "prepared_set_encoded.columns = encoder.get_feature_names_out(categorical_cols)\n",
    " \n",
    "# Drop the original categorical columns\n",
    "prepared_set.drop(categorical_cols, axis=1, inplace=True)\n",
    "\n",
    "# Reset the indices of the dataframes\n",
    "prepared_set = prepared_set.reset_index(drop=True)\n",
    "prepared_set_encoded = prepared_set_encoded.reset_index(drop=True)\n",
    "\n",
    "# Concatenate the original DataFrame with the one-hot encoded DataFrame\n",
    "prepared_set = pd.concat([prepared_set, prepared_set_encoded], axis=1)\n",
    "\n",
    "prepared_set.info()"
   ],
   "id": "fa9a4e102c412168",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Primitive Approach",
   "id": "e7493800d9c2da15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "primitive_set = prepared_set.copy()\n",
    "\n",
    "X = primitive_set.drop('churn', axis=1)\n",
    "y = primitive_set['churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = RidgeClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ],
   "id": "f3e300f71a5afe6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "primitive_mse = mean_squared_error(y_test, y_pred)\n",
    "primitive_mae = mean_absolute_error(y_test, y_pred)\n",
    "primitive_r2 = r2_score(y_test, y_pred)\n",
    "primitive_accuracy = accuracy_score(y_test, y_pred)\n",
    "primitive_precision = precision_score(y_test, y_pred)\n",
    "primitive_recall = recall_score(y_test, y_pred)\n",
    "primitive_f1 = f1_score(y_test, y_pred)\n",
    "primitive_roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\n",
    "    f\"MSE: {primitive_mse}\\nMAE: {primitive_mae}\\nR2: {primitive_r2}\\nAccuracy: {primitive_accuracy}\\nPrecision: {primitive_precision}\\nRecall: {primitive_recall}\\nF1 Score: {primitive_f1}\\nROC AUC: {primitive_roc_auc}\")"
   ],
   "id": "dd6e19442a6e9e2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# My Model\n",
    "## Define Target and Feauture Variables & Split and Scale Set\n",
    "Split the data into training, validation, and test sets, then, standardise the features"
   ],
   "id": "d68ea014d8ac8fd0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "better_model = prepared_set.copy()\n",
    "\n",
    "# Define Target and feature variables\n",
    "y = better_model['churn'].values\n",
    "X = better_model.drop(['churn'], axis=1)\n",
    "\n",
    "# Extract feature names\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "# Perform train-validation-test split\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X[feature_names], y, test_size=0.3, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.285, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_train_val = scaler.transform(X_train_val)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "id": "b4f9b3e5212ee39c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def beep():\n",
    "    duration = 5000\n",
    "    freq = 1000\n",
    "    winsound.Beep(freq, duration)"
   ],
   "id": "6c87ead3c320e2ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train and Evaluate Models",
   "id": "f23d302e37174edf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Perform hyperparameter tuning for the RandomForest model using randomised search. Print the best hyperparameters and the corresponding Recall(on subset of training set(Cross-Validation)) score.",
   "id": "96710e907a3822d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "param_grid = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator=rf_model, param_distributions=param_grid, n_iter=100, cv=3, verbose=2,random_state=42, n_jobs=-1, scoring='recall')\n",
    "\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "print(rf_random.best_score_) # 0.9959059371040283\n",
    "print(rf_random.best_params_) # {'n_estimators': 1800, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 80, 'bootstrap': False}\n",
    "# Runtime 2h 51m 14s\n",
    "beep()"
   ],
   "id": "608be9ae21b52b72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Perform hyperparameter tuning for the XGBoost model using randomised search. Print the best hyperparameters and the corresponding Recall(on subset of training set(Cross-Validation)) score.",
   "id": "33dff5ca10d0906c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.05, 0.1, 0.20, 0.30],\n",
    "    'n_estimators': [100, 400, 800],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'min_child_weight': [1, 10, 100],\n",
    "    'colsample_bytree': [0.5, 0.7, 1.0],\n",
    "    'subsample': [0.5, 0.7, 1.0]\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "xgb_random = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_grid, n_iter=300, cv=3, verbose=2, n_jobs=-1, scoring='recall')\n",
    "\n",
    "xgb_random.fit(X_train, y_train)\n",
    "\n",
    "print(xgb_random.best_score_) # 0.9973181753786369\n",
    "print(xgb_random.best_params_) # {'subsample': 1.0, 'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
    "# Runtime 1h 47m 7s\n",
    "beep()"
   ],
   "id": "b8b36e8e5905f119",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Perform hyperparameter tuning for the LightGBM using grid search. Print the best hyperparameters and the corresponding Recall(on subset of training set(Cross-Validation)) score.",
   "id": "70f32b6862f07654"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the parameter lgbm_grid\n",
    "param_grid = {\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'num_leaves': [31, 62, 93],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Create a LightGBM model\n",
    "lgbm_model = lgb.LGBMClassifier()\n",
    "\n",
    "# Create the lgbm_grid search object\n",
    "lgbm_grid = GridSearchCV(lgbm_model, param_grid, cv=5, scoring='recall')\n",
    "\n",
    "# Fit the lgbm_grid search object to the data\n",
    "lgbm_grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the corresponding score\n",
    "print(lgbm_grid.best_params_) # {'learning_rate': 0.1, 'max_depth': 30, 'n_estimators': 100, 'num_leaves': 93}\n",
    "print(lgbm_grid.best_score_) # 0.9991155677841\n",
    "# Runtime 8m 31s 633ms\n",
    "beep()"
   ],
   "id": "3ed3b8797e3b26a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Perform hyperparameter tuning for the Decision Tree model using grid search. Print the best hyperparameters and the corresponding Recall(on subset of training set(Cross-Validation)) score",
   "id": "eaeff307ed7a388f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the parameter tree_grid\n",
    "param_grid = {\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [1.0, 'sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Create a DecisionTreeRegressor model\n",
    "decTree_model = DecisionTreeClassifier()\n",
    "\n",
    "#Create the tree_grid search object\n",
    "tree_grid = GridSearchCV(decTree_model, param_grid, cv=5, scoring=\"recall\", verbose=1)\n",
    "\n",
    "# fit the tree_grid search object to the data\n",
    "tree_grid.fit(X_train, y_train)\n",
    "\n",
    "#Print the best parameters and the corresponding score\n",
    "print(tree_grid.best_params_)  # {'max_depth': 10, 'max_features': 1.0, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
    "print(tree_grid.best_score_)  # 0.9912056159258545\n",
    "# Runtime 7m 22s 647ms\n",
    "beep()"
   ],
   "id": "ed6e46dd7b0ddd3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_pred_rf = rf_random.best_estimator_.predict(X_val)\n",
    "y_pred_xgb = xgb_random.best_estimator_.predict(X_val)\n",
    "y_pred_lgbm = lgbm_grid.best_estimator_.predict(X_val)\n",
    "y_pred_tree = tree_grid.best_estimator_.predict(X_val)"
   ],
   "id": "2219638140e639e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Accuracy, Precision, Recall, F1 Score and ROC AUC\n",
    "# Calculate the performance metrics\n",
    "rf_accuracy = accuracy_score(y_val, y_pred_rf)\n",
    "rf_precision = precision_score(y_val, y_pred_rf)\n",
    "rf_recall = recall_score(y_val, y_pred_rf)\n",
    "rf_f1 = f1_score(y_val, y_pred_rf)\n",
    "rf_roc_auc = roc_auc_score(y_val, y_pred_rf)\n",
    "\n",
    "xgb_accuracy = accuracy_score(y_val, y_pred_xgb)\n",
    "xgb_precision = precision_score(y_val, y_pred_xgb)\n",
    "xgb_recall = recall_score(y_val, y_pred_xgb)\n",
    "xgb_f1 = f1_score(y_val, y_pred_xgb)\n",
    "xgb_roc_auc = roc_auc_score(y_val, y_pred_xgb)\n",
    "\n",
    "lgbm_accuracy = accuracy_score(y_val, y_pred_lgbm)\n",
    "lgbm_precision = precision_score(y_val, y_pred_lgbm)\n",
    "lgbm_recall = recall_score(y_val, y_pred_lgbm)\n",
    "lgbm_f1 = f1_score(y_val, y_pred_lgbm)\n",
    "lgbm_roc_auc = roc_auc_score(y_val, y_pred_lgbm)\n",
    "\n",
    "tree_accuracy = accuracy_score(y_val, y_pred_tree)\n",
    "tree_precision = precision_score(y_val, y_pred_tree)\n",
    "tree_recall = recall_score(y_val, y_pred_tree)\n",
    "tree_f1 = f1_score(y_val, y_pred_tree)\n",
    "tree_roc_auc = roc_auc_score(y_val, y_pred_tree)\n",
    "\n",
    "models = ['Random Forest (Validation Set)', 'XGBoost (Validation Set)', 'LightGBM (Validation Set)', 'Decision Tree (Validation Set)']\n",
    "accuracy_values = [rf_accuracy, xgb_accuracy, lgbm_accuracy, tree_accuracy]\n",
    "precision_values = [rf_precision, xgb_precision, lgbm_precision, tree_precision]\n",
    "recall_values = [rf_recall, xgb_recall, lgbm_recall, tree_recall]\n",
    "f1_values = [rf_f1, xgb_f1, lgbm_f1, tree_f1]\n",
    "roc_auc_values = [rf_roc_auc, xgb_roc_auc, lgbm_roc_auc, tree_roc_auc]"
   ],
   "id": "eaf9e3f4f471e82b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def print_values(values, models, title):\n",
    "    print(title)\n",
    "    for model, value in zip(models, values):\n",
    "        print(f\"{model}: {value}\")\n",
    "\n",
    "def plot_values(values, title, models, ylabel):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    sns.barplot(x=models, y=values)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ],
   "id": "52bb489cba5285da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print_values(accuracy_values, models, 'Comparison of Accuracy')\n",
    "print_values(precision_values, models, 'Comparison of Precision')\n",
    "print_values(recall_values, models, 'Comparison of Recall')\n",
    "print_values(f1_values, models, 'Comparison of F1 Score')\n",
    "print_values(roc_auc_values, models, 'Comparison of ROC AUC')"
   ],
   "id": "8372c97edbf027ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_values(accuracy_values, 'Comparison of Accuracy', models, 'Accuracy')\n",
    "plot_values(precision_values, 'Comparison of Precision', models, 'Precision')\n",
    "plot_values(recall_values, 'Comparison of Recall', models, 'Recall')\n",
    "plot_values(f1_values, 'Comparison of F1 Score', models, 'F1 Score')\n",
    "plot_values(roc_auc_values, 'Comparison of ROC AUC', models, 'ROC AUC')"
   ],
   "id": "ecde03aa9069e59b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_confusion_matrix(y_val, y_pred_rf, 'Random Forest Confusion Matrix')\n",
    "plot_confusion_matrix(y_val, y_pred_xgb, 'XGBoost Confusion Matrix')\n",
    "plot_confusion_matrix(y_val, y_pred_lgbm, 'LightGBM Confusion Matrix')\n",
    "plot_confusion_matrix(y_val, y_pred_tree, 'Decision Tree Confusion Matrix')"
   ],
   "id": "326689b1311b49b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Implement the Stacking Classifier using the best models and hyperparameters obtained from the previous steps.",
   "id": "ded19a73e7384a6e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rf_best_params = {'n_estimators': 1800, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 80, 'bootstrap': False}\n",
    "xgb_best_params = {'subsample': 1.0, 'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 9, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
    "lgbm_best_params = {'learning_rate': 0.1, 'max_depth': 30, 'n_estimators': 100, 'num_leaves': 93}\n",
    "tree_best_params = {'max_depth': 10, 'max_features': 1.0, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
    "\n",
    "base_models = [\n",
    "    ('Random Forest', RandomForestClassifier(**rf_best_params)),\n",
    "    ('XGBoost', xgb.XGBClassifier(**xgb_best_params)),\n",
    "    ('LightGBM', lgb.LGBMClassifier(**lgbm_best_params)),\n",
    "    ('Decision Tree', DecisionTreeClassifier(**tree_best_params))\n",
    "]\n",
    "\n",
    "meta_model = lgb.LGBMClassifier()\n",
    "\n",
    "stacked_model = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5, verbose=2)"
   ],
   "id": "e1047c5cc296ee96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "stacked_model.fit(X_train, y_train)\n",
    "beep()"
   ],
   "id": "771bbde1eb6cfd65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rf_model = RandomForestClassifier(**rf_best_params)\n",
    "rf_model.fit(X_train, y_train)\n",
    "beep()"
   ],
   "id": "4e0aad6ab1f0f96e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "xgb_model = xgb.XGBClassifier(**xgb_best_params)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "beep()"
   ],
   "id": "321d71ec8915b6ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lgbm_model = lgb.LGBMClassifier(**lgbm_best_params)\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "beep()"
   ],
   "id": "193ec2e910d6db09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "decTree_model = DecisionTreeClassifier(**tree_best_params)\n",
    "decTree_model.fit(X_train, y_train)\n",
    "beep()"
   ],
   "id": "6f8582de67f37e7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate all the models on the validation set",
   "id": "6ace23923d55b98"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Predict validation set and calculate performance matrices\n",
    "y_val_pred_rf = rf_model.predict(X_val)\n",
    "y_val_pred_xgb = xgb_model.predict(X_val)\n",
    "y_val_pred_lgbm = lgbm_model.predict(X_val)\n",
    "y_val_pred_tree = decTree_model.predict(X_val)\n",
    "y_val_stack = stacked_model.predict(X_val)\n",
    "\n",
    "# Calculate the performance metrics\n",
    "stack_accuracy = accuracy_score(y_val, y_val_stack)\n",
    "stack_precision = precision_score(y_val, y_val_stack)\n",
    "stack_recall = recall_score(y_val, y_val_stack)\n",
    "stack_f1 = f1_score(y_val, y_val_stack)\n",
    "stack_roc_auc = roc_auc_score(y_val, y_val_stack)\n",
    "\n",
    "rf_accuracy = accuracy_score(y_val, y_val_pred_rf)\n",
    "rf_precision = precision_score(y_val, y_val_pred_rf)\n",
    "rf_recall = recall_score(y_val, y_val_pred_rf)\n",
    "rf_f1 = f1_score(y_val, y_val_pred_rf)\n",
    "rf_roc_auc = roc_auc_score(y_val, y_val_pred_rf)\n",
    "\n",
    "xgb_accuracy = accuracy_score(y_val, y_val_pred_xgb)\n",
    "xgb_precision = precision_score(y_val, y_val_pred_xgb)\n",
    "xgb_recall = recall_score(y_val, y_val_pred_xgb)\n",
    "xgb_f1 = f1_score(y_val, y_val_pred_xgb)\n",
    "xgb_roc_auc = roc_auc_score(y_val, y_val_pred_xgb)\n",
    "\n",
    "lgbm_accuracy = accuracy_score(y_val, y_val_pred_lgbm)\n",
    "lgbm_precision = precision_score(y_val, y_val_pred_lgbm)\n",
    "lgbm_recall = recall_score(y_val, y_val_pred_lgbm)\n",
    "lgbm_f1 = f1_score(y_val, y_val_pred_lgbm)\n",
    "lgbm_roc_auc = roc_auc_score(y_val, y_val_pred_lgbm)\n",
    "\n",
    "tree_accuracy = accuracy_score(y_val, y_val_pred_tree)\n",
    "tree_precision = precision_score(y_val, y_val_pred_tree)\n",
    "tree_recall = recall_score(y_val, y_val_pred_tree)\n",
    "tree_f1 = f1_score(y_val, y_val_pred_tree)\n",
    "tree_roc_auc = roc_auc_score(y_val, y_val_pred_tree)\n",
    "\n",
    "models = ['Stacking (Validation Set)', 'Random Forest (Validation Set)', 'XGBoost (Validation Set)', 'LightGBM (Validation Set)', 'Decision Tree (Validation Set)']\n",
    "accuracy_values = [stack_accuracy, rf_accuracy, xgb_accuracy, lgbm_accuracy, tree_accuracy]\n",
    "precision_values = [stack_precision, rf_precision, xgb_precision, lgbm_precision, tree_precision]\n",
    "recall_values = [stack_recall, rf_recall, xgb_recall, lgbm_recall, tree_recall]\n",
    "f1_values = [stack_f1, rf_f1, xgb_f1, lgbm_f1, tree_f1]\n",
    "roc_auc_values = [stack_roc_auc, rf_roc_auc, xgb_roc_auc, lgbm_roc_auc, tree_roc_auc]"
   ],
   "id": "bd0ca1b2d0906e02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print_values(accuracy_values, models, 'Comparison of Accuracy')\n",
    "print_values(precision_values, models, 'Comparison of Precision')\n",
    "print_values(recall_values, models, 'Comparison of Recall')\n",
    "print_values(f1_values, models, 'Comparison of F1 Score')\n",
    "print_values(roc_auc_values, models, 'Comparison of ROC AUC')"
   ],
   "id": "40f4b28838801404",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_confusion_matrix(y_val, y_val_stack, 'Stacking Confusion Matrix (Validation Set)')\n",
    "plot_confusion_matrix(y_val, y_val_pred_rf, 'Random Forest Confusion Matrix (Validation Set)')\n",
    "plot_confusion_matrix(y_val, y_val_pred_xgb, 'XGBoost Confusion Matrix (Validation Set)')\n",
    "plot_confusion_matrix(y_val, y_val_pred_lgbm, 'LightGBM Confusion Matrix (Validation Set)')\n",
    "plot_confusion_matrix(y_val, y_val_pred_tree, 'Decision Tree Confusion Matrix (Validation Set)')"
   ],
   "id": "840a84e2fdfe97a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate the models on the test set",
   "id": "e719747abbab6a68"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Predict test set and calculate performance matrices\n",
    "y_test_pred_rf = rf_model.predict(X_test)\n",
    "y_test_pred_xgb = xgb_model.predict(X_test)\n",
    "y_test_pred_lgbm = lgbm_model.predict(X_test)\n",
    "y_test_pred_tree = decTree_model.predict(X_test)\n",
    "y_test_stack = stacked_model.predict(X_test)\n",
    "\n",
    "# Calculate the performance metrics\n",
    "stack_accuracy = accuracy_score(y_test, y_test_stack)\n",
    "stack_precision = precision_score(y_test, y_test_stack)\n",
    "stack_recall = recall_score(y_test, y_test_stack)\n",
    "stack_f1 = f1_score(y_test, y_test_stack)\n",
    "stack_roc_auc = roc_auc_score(y_test, y_test_stack)\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, y_test_pred_rf)\n",
    "rf_precision = precision_score(y_test, y_test_pred_rf)\n",
    "rf_recall = recall_score(y_test, y_test_pred_rf)\n",
    "rf_f1 = f1_score(y_test, y_test_pred_rf)\n",
    "rf_roc_auc = roc_auc_score(y_test, y_test_pred_rf)\n",
    "\n",
    "xgb_accuracy = accuracy_score(y_test, y_test_pred_xgb)\n",
    "xgb_precision = precision_score(y_test, y_test_pred_xgb)\n",
    "xgb_recall = recall_score(y_test, y_test_pred_xgb)\n",
    "xgb_f1 = f1_score(y_test, y_test_pred_xgb)\n",
    "xgb_roc_auc = roc_auc_score(y_test, y_test_pred_xgb)\n",
    "\n",
    "lgbm_accuracy = accuracy_score(y_test, y_test_pred_lgbm)\n",
    "lgbm_precision = precision_score(y_test, y_test_pred_lgbm)\n",
    "lgbm_recall = recall_score(y_test, y_test_pred_lgbm)\n",
    "lgbm_f1 = f1_score(y_test, y_test_pred_lgbm)\n",
    "lgbm_roc_auc = roc_auc_score(y_test, y_test_pred_lgbm)\n",
    "\n",
    "tree_accuracy = accuracy_score(y_test, y_test_pred_tree)\n",
    "tree_precision = precision_score(y_test, y_test_pred_tree)\n",
    "tree_recall = recall_score(y_test, y_test_pred_tree)\n",
    "tree_f1 = f1_score(y_test, y_test_pred_tree)\n",
    "tree_roc_auc = roc_auc_score(y_test, y_test_pred_tree)\n",
    "\n",
    "models = ['Stacking (Test Set)', 'Random Forest (Test Set)', 'XGBoost (Test Set)', 'LightGBM (Test Set)', 'Decision Tree (Test Set)']\n",
    "accuracy_values = [stack_accuracy, rf_accuracy, xgb_accuracy, lgbm_accuracy, tree_accuracy]\n",
    "precision_values = [stack_precision, rf_precision, xgb_precision, lgbm_precision, tree_precision]\n",
    "recall_values = [stack_recall, rf_recall, xgb_recall, lgbm_recall, tree_recall]\n",
    "f1_values = [stack_f1, rf_f1, xgb_f1, lgbm_f1, tree_f1]\n",
    "roc_auc_values = [stack_roc_auc, rf_roc_auc, xgb_roc_auc, lgbm_roc_auc, tree_roc_auc]"
   ],
   "id": "b2e974998bb7a13d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print_values(accuracy_values, models, 'Comparison of Accuracy')\n",
    "print_values(precision_values, models, 'Comparison of Precision')\n",
    "print_values(recall_values, models, 'Comparison of Recall')\n",
    "print_values(f1_values, models, 'Comparison of F1 Score')\n",
    "print_values(roc_auc_values, models, 'Comparison of ROC AUC')"
   ],
   "id": "75fa1872cd80e664",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_confusion_matrix(y_test, y_test_stack, 'Stacking Confusion Matrix (Test Set)')\n",
    "plot_confusion_matrix(y_test, y_test_pred_rf, 'Random Forest Confusion Matrix (Test Set)')\n",
    "plot_confusion_matrix(y_test, y_test_pred_xgb, 'XGBoost Confusion Matrix (Test Set)')\n",
    "plot_confusion_matrix(y_test, y_test_pred_lgbm, 'LightGBM Confusion Matrix (Test Set)')\n",
    "plot_confusion_matrix(y_test, y_test_pred_tree, 'Decision Tree Confusion Matrix (Test Set)')"
   ],
   "id": "c287cb79365343ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2nd Attempt with best params from base model for meta model",
   "id": "2c58298d70b52459"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "meta_model = lgb.LGBMClassifier(**lgbm_best_params)\n",
    "second_stacked_model = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5, verbose=2)"
   ],
   "id": "479e5362c7cc0448",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "second_stacked_model.fit(X_train, y_train)\n",
    "beep()"
   ],
   "id": "c1d218ed5bd0686f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Predict validation set and calculate performance matrices\n",
    "y_val_stack = stacked_model.predict(X_val)\n",
    "second_y_val_stack = second_stacked_model.predict(X_val)\n",
    "\n",
    "y_test_stack = stacked_model.predict(X_test)\n",
    "second_y_test_stack = second_stacked_model.predict(X_test)\n",
    "\n",
    "# Calculate the performance metrics\n",
    "y_val_stack_accuracy = accuracy_score(y_val, y_val_stack)\n",
    "y_val_stack_precision = precision_score(y_val, y_val_stack)\n",
    "y_val_stack_recall = recall_score(y_val, y_val_stack)\n",
    "y_val_stack_f1 = f1_score(y_val, y_val_stack)\n",
    "y_val_stack_roc_auc = roc_auc_score(y_val, y_val_stack)\n",
    "\n",
    "second_val_stack_accuracy = accuracy_score(y_val, second_y_val_stack)\n",
    "second_val_stack_precision = precision_score(y_val, second_y_val_stack)\n",
    "second_val_stack_recall = recall_score(y_val, second_y_val_stack)\n",
    "second_val_stack_f1 = f1_score(y_val, second_y_val_stack)\n",
    "second_val_stack_roc_auc = roc_auc_score(y_val, second_y_val_stack)\n",
    "\n",
    "\n",
    "y_test_stack_accuracy = accuracy_score(y_test, y_test_stack)\n",
    "y_test_stack_precision = precision_score(y_test, y_test_stack)\n",
    "y_test_stack_recall = recall_score(y_test, y_test_stack)\n",
    "y_test_stack_f1 = f1_score(y_test, y_test_stack)\n",
    "y_test_stack_roc_auc = roc_auc_score(y_test, y_test_stack)\n",
    "\n",
    "second_test_stack_accuracy = accuracy_score(y_test, second_y_test_stack)\n",
    "second_test_stack_precision = precision_score(y_test, second_y_test_stack)\n",
    "second_test_stack_recall = recall_score(y_test, second_y_test_stack)\n",
    "second_test_stack_f1 = f1_score(y_test, second_y_test_stack)\n",
    "second_test_stack_roc_auc = roc_auc_score(y_test, second_y_test_stack)\n",
    "\n",
    "models = ['Stacking (Validation Set)', 'Stacking (Test Set)', '2nd Stacking (Validation Set)', '2nd Stacking (Test Set)']\n",
    "accuracy_values = [y_val_stack_accuracy, y_test_stack_accuracy, second_val_stack_accuracy, second_test_stack_accuracy]\n",
    "precision_values = [y_val_stack_precision, y_test_stack_precision, second_val_stack_precision, second_test_stack_precision]\n",
    "recall_values = [y_val_stack_recall, y_test_stack_recall, second_val_stack_recall, second_test_stack_recall]\n",
    "f1_values = [y_val_stack_f1, y_test_stack_f1, second_val_stack_f1, second_test_stack_f1]\n",
    "roc_auc_values = [y_val_stack_roc_auc, y_test_stack_roc_auc, second_val_stack_roc_auc, second_test_stack_roc_auc]\n",
    "\n",
    "print_values(accuracy_values, models, 'Comparison of Accuracy')\n",
    "print_values(precision_values, models, 'Comparison of Precision')\n",
    "print_values(recall_values, models, 'Comparison of Recall')\n",
    "print_values(f1_values, models, 'Comparison of F1 Score')\n",
    "print_values(roc_auc_values, models, 'Comparison of ROC AUC')\n",
    "\n",
    "plot_confusion_matrix(y_val, y_val_stack, 'Stacking Confusion Matrix (Validation Set)')\n",
    "plot_confusion_matrix(y_val, second_y_val_stack, '2nd Stacking Confusion Matrix (Validation Set)')\n",
    "plot_confusion_matrix(y_test, y_test_stack, 'Stacking Confusion Matrix (Test Set)')\n",
    "plot_confusion_matrix(y_test, second_y_test_stack, '2nd Stacking Confusion Matrix (Test Set)')"
   ],
   "id": "d3a3b92903eb18a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "beep()",
   "id": "2d17f9d2b1af269b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
