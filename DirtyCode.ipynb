{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The Dataset contains the following 12 features:\n",
    "\n",
    "CustomerID: A unique identifier\n",
    "\n",
    "Age: The age of the customer\n",
    "\n",
    "Gender: The gender of the customer\n",
    "\n",
    "Tenure: The number of months the customer has stayed with the company\n",
    "\n",
    "Usage Frequency: The number of times the customer has used the service the past month\n",
    "\n",
    "Support calls: The number of support calls the customer has made the past month\n",
    "\n",
    "Payment Delay: Number of days the customer has delayed payment the past month\n",
    "\n",
    "Subscription Type: The type of subscription the customer has\n",
    "\n",
    "Contract Length: Duration of the contract\n",
    "\n",
    "Total Spend: The total amount the customer has spent\n",
    "\n",
    "Last Interaction: Number of days since the last interaction the customer has had with the company\n",
    "\n",
    "Churn: Whether the customer has churned or not"
   ],
   "id": "9d1fbd99fdf5df0d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import packages",
   "id": "eb52de71c88559da"
  },
  {
   "cell_type": "code",
   "id": "af274228a76fce1a",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-02T18:12:12.431689Z",
     "start_time": "2024-07-02T18:12:12.418597Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import lightgbm as lgb\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cleanup",
   "id": "e5aa3d024b73091a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_set_dirty = pd.read_csv(\"Datasets/In/customer_churn_dataset-testing-master.csv\", sep=\",\")\n",
    "training_set_dirty = pd.read_csv(\"Datasets/In/customer_churn_dataset-training-master.csv\", sep=\",\")\n",
    "\n",
    "combined_set_dirty = pd.concat([training_set_dirty, test_set_dirty], ignore_index=True)\n",
    "combined_set_dirty = combined_set_dirty.drop(combined_set_dirty.columns[0], axis=1)\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "missing_values = combined_set_dirty.isnull().sum()\n",
    "missing_values"
   ],
   "id": "3a5f283dfd9c40ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "combined_set_dirty[combined_set_dirty.isna().any(axis=1)]",
   "id": "7291a6e82abe9500",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# remove row with missing values\n",
    "combined_set_dirty.dropna(inplace=True)\n",
    "\n",
    "combined_set_dirty.columns = [col.lower().replace(\" \", \"_\") for col in combined_set_dirty.columns]\n",
    "combined_set_dirty.info()"
   ],
   "id": "521699c3f844d8dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "combined_set_dirty[combined_set_dirty.isna().any(axis=1)]",
   "id": "386edb816ee447ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "numerals = [\"age\", \"tenure\", \"usage_frequency\", \"support_calls\", \"payment_delay\", \"last_interaction\", \"churn\"]\n",
    "\n",
    "for col in numerals:\n",
    "    combined_set_dirty[col] = combined_set_dirty[col].astype(int)\n",
    "    "
   ],
   "id": "7a7258d15a4fea7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Create a label encoder object\n",
    "# le = LabelEncoder()\n",
    "# \n",
    "# # List of columns you want to convert\n",
    "# columns_to_convert = ['gender', 'subscription_type', 'contract_length']\n",
    "# \n",
    "# # Apply the label encoder to each column and print the mapping\n",
    "# for column in columns_to_convert:\n",
    "#     combined_set_dirty[column] = le.fit_transform(combined_set_dirty[column])\n",
    "#     print(f\"Mapping for {column}:\")\n",
    "#     for class_, label in zip(le.classes_, range(len(le.classes_))):\n",
    "#         print(f\"{class_} -> {label}\")\n",
    "#     print(\"\\n\")"
   ],
   "id": "9e308f344b590636",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cleaned_set = combined_set_dirty.copy()",
   "id": "51aa90d8e640ea87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Descriptive Analytics",
   "id": "c29154d4aca422a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Summary statistics\n",
    "print(\"Summary Statistics for Churned Customers:\")\n",
    "print(cleaned_set[cleaned_set['churn'] == 1].describe())\n",
    "print(\"\\nSummary Statistics for Non-Churned Customers:\")\n",
    "print(cleaned_set[cleaned_set['churn'] == 0].describe())\n",
    "\n",
    "# Distribution of categorical variables\n",
    "categorical_columns = ['gender', 'subscription_type', 'contract_length']\n",
    "for column in categorical_columns:\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.countplot(data=cleaned_set, x=column, hue='churn')\n",
    "    plt.title(f'Distribution of {column} for Churned and Non-Churned Customers')\n",
    "    plt.show()\n",
    "\n",
    "# Correlation analysis\n",
    "correlation = cleaned_set.corr()\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Churn rate\n",
    "churn_rate = cleaned_set['churn'].mean() * 100\n",
    "print(f\"Churn Rate: {churn_rate}%\")"
   ],
   "id": "94855a09b7c82e34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "numeric_cols = [\"age\", \"tenure\", \"usage_frequency\", \"support_calls\", \"payment_delay\", \"last_interaction\", \"total_spend\"]\n",
    "\n",
    "num_bins = 3\n",
    "\n",
    "excourse_set = cleaned_set.copy()\n",
    "\n",
    "for col in numeric_cols:\n",
    "    excourse_set[col] = pd.cut(cleaned_set[col], num_bins, duplicates='drop')\n",
    "    print(col)\n",
    "    for interval in excourse_set[col].cat.categories:\n",
    "        print(interval)"
   ],
   "id": "a1670fa2ee6fbd71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "columns = [\"age\", \"gender\", \"tenure\", \"usage_frequency\", \"support_calls\", \"payment_delay\", \"subscription_type\", \"contract_length\", \"total_spend\", \"last_interaction\"]\n",
    "\n",
    "stacked_data_percent = {}\n",
    "\n",
    "for col in columns:\n",
    "    category_counts = excourse_set.groupby([col, \"churn\"]).size().unstack(fill_value=0)\n",
    "    \n",
    "    category_percent = category_counts.div(category_counts.sum(axis=1), axis=0) * 100\n",
    "    print(category_percent)\n",
    "    stacked_data_percent[col] = category_percent\n",
    "    "
   ],
   "id": "129bd3f3c68f5921",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate the overall churn rate\n",
    "overall_churn_rate = excourse_set['churn'].mean() * 100\n",
    "\n",
    "# Add a new row to each DataFrame in stacked_data_percent with the overall churn rate\n",
    "for col, df in stacked_data_percent.items():\n",
    "    df.loc['Overall'] = [100 - overall_churn_rate, overall_churn_rate]\n",
    "    \n",
    "colors = {0: 'green', 1: 'red'}\n",
    "for col, df in stacked_data_percent.items():\n",
    "    ax = df.plot(kind='barh', stacked=True, color=[colors[churn] for churn in df.columns],\n",
    "                 title=f'Percentage Chart of Churned Customers in {col}')\n",
    "    plt.ylabel(col)\n",
    "    plt.xlabel('Percentage')\n",
    "    plt.legend([\"No Churn\", \"Churn\"], loc='best')\n",
    "\n",
    "    # Add the percentage values on each bar\n",
    "    for p in ax.patches:\n",
    "        width = p.get_width()\n",
    "        height = p.get_height()\n",
    "        x, y = p.get_xy()\n",
    "        ax.text(x+width/2,\n",
    "                y+height/2,\n",
    "                '{:.1f} %'.format(width),\n",
    "                horizontalalignment='center',\n",
    "                verticalalignment='center')\n",
    "    plt.show()"
   ],
   "id": "5765c52a8a7fe3a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "combinations = list(itertools.combinations(columns, 2))\n",
    "\n",
    "# Analyze each combination\n",
    "for combination in combinations:\n",
    "    # Create a multi-index DataFrame\n",
    "    multi_index_df = excourse_set.set_index(list(combination) + ['churn'])\n",
    "\n",
    "    # Calculate the size of each group\n",
    "    grouped_df = multi_index_df.groupby(list(combination) + ['churn']).size()\n",
    "\n",
    "    # Unstack the DataFrame to get a cross-tabulation\n",
    "    cross_tab = grouped_df.unstack(fill_value=0)\n",
    "\n",
    "    # Convert absolute numbers to relative percentages\n",
    "    cross_tab_percent = cross_tab.div(cross_tab.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    # Print the cross-tabulation\n",
    "    print(f\"Cross-tabulation for {combination}:\")\n",
    "    print(cross_tab_percent)\n",
    "    print(\"\\n\")"
   ],
   "id": "5dc8f5611d13dc46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "combinations = list(itertools.combinations(columns, 3))\n",
    "\n",
    "# Analyze each combination\n",
    "for combination in combinations:\n",
    "    # Create a multi-index DataFrame\n",
    "    multi_index_df = excourse_set.set_index(list(combination) + ['churn'])\n",
    "\n",
    "    # Calculate the size of each group\n",
    "    grouped_df = multi_index_df.groupby(list(combination) + ['churn']).size()\n",
    "\n",
    "    # Unstack the DataFrame to get a cross-tabulation\n",
    "    cross_tab = grouped_df.unstack(fill_value=0)\n",
    "\n",
    "    # Convert absolute numbers to relative percentages\n",
    "    cross_tab_percent = cross_tab.div(cross_tab.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    # Print the cross-tabulation\n",
    "    print(f\"Cross-tabulation for {combination}:\")\n",
    "    print(cross_tab_percent)\n",
    "    print(\"\\n\")"
   ],
   "id": "f7109f9988cac69e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Predictive Analytics\n",
    "## Primitive Approach"
   ],
   "id": "92fe04358e315dd3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prepared_set = cleaned_set.copy()\n",
    "\n",
    "# Create a OneHotEncoder instance\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = ['gender', 'subscription_type', 'contract_length']\n",
    "\n",
    "# Fit and transform the data, converting it into a DataFrame\n",
    "prepared_set_encoded = pd.DataFrame(encoder.fit_transform(prepared_set[categorical_cols]))\n",
    "\n",
    "# Get feature names from the encoder and assign them as column names\n",
    "prepared_set_encoded.columns = encoder.get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Drop the original categorical columns\n",
    "prepared_set.drop(categorical_cols, axis=1, inplace=True)\n",
    "\n",
    "# Reset the indices of the dataframes\n",
    "prepared_set = prepared_set.reset_index(drop=True)\n",
    "prepared_set_encoded = prepared_set_encoded.reset_index(drop=True)\n",
    "\n",
    "# Concatenate the original DataFrame with the one-hot encoded DataFrame\n",
    "prepared_set = pd.concat([prepared_set, prepared_set_encoded], axis=1)\n",
    "\n",
    "prepared_set.info()"
   ],
   "id": "2c3a204f8b5fde19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "primitive_set = prepared_set.copy()\n",
    "\n",
    "X = primitive_set.drop('churn', axis=1)\n",
    "y = primitive_set['churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n"
   ],
   "id": "bfda46308fe5ba5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate the performance metrics\n",
    "\n",
    "# Predict the probabilities of the positive class\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "primitive_mse = mean_squared_error(y_test, y_pred)\n",
    "primitive_mae = mean_absolute_error(y_test, y_pred)\n",
    "primitive_r2 = r2_score(y_test, y_pred)\n",
    "primitive_accuracy = accuracy_score(y_test, y_pred)\n",
    "primitive_precision = precision_score(y_test, y_pred)\n",
    "primitive_recall = recall_score(y_test, y_pred)\n",
    "primitive_f1 = f1_score(y_test, y_pred)\n",
    "primitive_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"MSE: {primitive_mse}\\nMAE: {primitive_mae}\\nR2: {primitive_r2}\\nAccuracy: {primitive_accuracy}\\nPrecision: {primitive_precision}\\nRecall: {primitive_recall}\\nF1 Score: {primitive_f1}\\nROC AUC: {primitive_roc_auc}\")"
   ],
   "id": "bef34fddc91311fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# My Model",
   "id": "9b3ba607804b7ef1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Define Target and Feauture Variables & Split and Scale Set\n",
    "Split the data into training, validation, and test sets, then, standardise the features"
   ],
   "id": "6a670e58e3acaca2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "better_model = prepared_set.copy()\n",
    "\n",
    "# Define Target and feature variables\n",
    "y = better_model['churn'].values\n",
    "X = better_model.drop(['churn'], axis=1)\n",
    "\n",
    "# Extract feature names\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "# Perform train-validation-test split\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X[feature_names], y, test_size=0.3, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.285, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_train_val = scaler.transform(X_train_val)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "id": "4d461c3142cb6327",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Train and Evaluate Models\n",
    "Perform hyperparameter tuning for the LightGBM using grid search. Print the best hyperparameters and the corresponding R-squared(on subset of training set(Cross-Validation)) score."
   ],
   "id": "e4dcf8a1dde95d9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the parameter lgbm_grid\n",
    "param_grid = {\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'num_leaves': [31, 62, 93],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Create a LightGBM model\n",
    "lgbm_model = lgb.LGBMRegressor()\n",
    "\n",
    "# Create the lgbm_grid search object\n",
    "lgbm_grid = GridSearchCV(lgbm_model, param_grid, cv=5, scoring='r2')\n",
    "\n",
    "# Fit the lgbm_grid search object to the data\n",
    "lgbm_grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the corresponding score\n",
    "print(lgbm_grid.best_params_)\n",
    "print(lgbm_grid.best_score_)"
   ],
   "id": "bee293cc8b8fd571",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Perform hyperparameter tuning for the Decision Tree model using grid search. Print the best hyperparameters and the corresponding R-squared(on subset of training set(Cross-Validation)) score",
   "id": "4660d9d9ff68a79e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the parameter tree_grid\n",
    "param_grid = {\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [1.0, 'sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Create a DecisionTreeRegressor model\n",
    "decTree_model = DecisionTreeRegressor()\n",
    "\n",
    "#Create the tree_grid search object\n",
    "tree_grid = GridSearchCV(decTree_model, param_grid, cv=5, scoring=\"r2\")\n",
    "\n",
    "# fit the tree_grid search object to the data\n",
    "tree_grid.fit(X_train, y_train)\n",
    "\n",
    "#Print the best parameters and the corresponding score\n",
    "print(tree_grid.best_params_)\n",
    "print(tree_grid.best_score_)"
   ],
   "id": "a86b237455604e46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the parameter xgb_grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'subsample': [0.5, 0.7, 1.0],\n",
    "    'colsample_bytree': [0.4, 0.7, 1.0]\n",
    "}\n",
    "print(\"check 1\")\n",
    "# Create model\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "print(\"check 2\")\n",
    "\n",
    "# Create grid search object\n",
    "xgb_grid = GridSearchCV(xgb_model, param_grid, cv=5, scoring='r2')\n",
    "print(\"check 3\")\n",
    "\n",
    "# Fit the xgb_grid search object to the data\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "print(\"check 4\")\n",
    "#Print the best  parameters and the corresponding score\n",
    "print(xgb_grid.best_params_)\n",
    "print(xgb_grid.best_score_)\n",
    "print(\"check 5\")\n",
    "\n",
    "importance_scores = xgb_grid.feature_importances_\n",
    "print(\"check 6\")\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importance_scores\n",
    "})\n",
    "print(\"check 7\")\n",
    "\n",
    "importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "print(\"check 8\")\n",
    "\n",
    "importance_df.plot(kind='bar', x='Feature', y='Importance', title='Feature Importance', figsize=(15, 6))\n",
    "plt.ylabel('Importance Score')\n",
    "plt.show()"
   ],
   "id": "7985f26c75b9aea7",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 19\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcheck 3\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# Fit the xgb_grid search object to the data\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m \u001B[43mxgb_grid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcheck 4\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m#Print the best  parameters and the corresponding score\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DSML_Team01\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    868\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    869\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    870\u001B[0m     )\n\u001B[0;32m    872\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 874\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    876\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    877\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    878\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DSML_Team01\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1386\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1387\u001B[0m     \u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1388\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DSML_Team01\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    813\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    814\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    815\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    816\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    817\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[0;32m    818\u001B[0m         )\n\u001B[0;32m    819\u001B[0m     )\n\u001B[1;32m--> 821\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    822\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    823\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    825\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    826\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    827\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    828\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    829\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    830\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    831\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    832\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    833\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    834\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    835\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    836\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    838\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    839\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    840\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    841\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    842\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    843\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DSML_Team01\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     58\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     59\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     60\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     61\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     62\u001B[0m )\n\u001B[1;32m---> 63\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DSML_Team01\\lib\\site-packages\\joblib\\parallel.py:1051\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1048\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n\u001B[0;32m   1049\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1051\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m   1052\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m   1054\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pre_dispatch \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mall\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1055\u001B[0m     \u001B[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001B[39;00m\n\u001B[0;32m   1056\u001B[0m     \u001B[38;5;66;03m# No need to wait for async callbacks to trigger to\u001B[39;00m\n\u001B[0;32m   1057\u001B[0m     \u001B[38;5;66;03m# consumption.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DSML_Team01\\lib\\site-packages\\joblib\\parallel.py:864\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    862\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    863\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 864\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    865\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DSML_Team01\\lib\\site-packages\\joblib\\parallel.py:782\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    780\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    781\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[1;32m--> 782\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    783\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[0;32m    784\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[0;32m    785\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[0;32m    786\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[0;32m    787\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DSML_Team01\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    207\u001B[0m     \u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[1;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[0;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DSML_Team01\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    569\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[0;32m    570\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[0;32m    571\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[1;32m--> 572\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DSML_Team01\\lib\\site-packages\\joblib\\parallel.py:263\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    259\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    260\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    261\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    262\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 263\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    264\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DSML_Team01\\lib\\site-packages\\joblib\\parallel.py:263\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    259\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    260\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    261\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    262\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 263\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    264\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DSML_Team01\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    121\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[1;32m--> 123\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DSML_Team01\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[0;32m    684\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[0;32m    685\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 686\u001B[0m         \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    688\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m    689\u001B[0m     \u001B[38;5;66;03m# Note fit time as time until error\u001B[39;00m\n\u001B[0;32m    690\u001B[0m     fit_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DSML_Team01\\lib\\site-packages\\xgboost\\core.py:620\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    618\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[0;32m    619\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[1;32m--> 620\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DSML_Team01\\lib\\site-packages\\xgboost\\sklearn.py:1025\u001B[0m, in \u001B[0;36mXGBModel.fit\u001B[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001B[0m\n\u001B[0;32m   1014\u001B[0m     obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1016\u001B[0m (\n\u001B[0;32m   1017\u001B[0m     model,\n\u001B[0;32m   1018\u001B[0m     metric,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1023\u001B[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001B[0;32m   1024\u001B[0m )\n\u001B[1;32m-> 1025\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1026\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1027\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dmatrix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1028\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_num_boosting_rounds\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1029\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevals\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1030\u001B[0m \u001B[43m    \u001B[49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1031\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevals_result\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals_result\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1032\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1033\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1034\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1035\u001B[0m \u001B[43m    \u001B[49m\u001B[43mxgb_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1036\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1037\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1039\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_evaluation_result(evals_result)\n\u001B[0;32m   1040\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DSML_Team01\\lib\\site-packages\\xgboost\\core.py:620\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    618\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[0;32m    619\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[1;32m--> 620\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DSML_Team01\\lib\\site-packages\\xgboost\\training.py:185\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001B[0m\n\u001B[0;32m    183\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cb_container\u001B[38;5;241m.\u001B[39mbefore_iteration(bst, i, dtrain, evals):\n\u001B[0;32m    184\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m--> 185\u001B[0m \u001B[43mbst\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    186\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cb_container\u001B[38;5;241m.\u001B[39mafter_iteration(bst, i, dtrain, evals):\n\u001B[0;32m    187\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DSML_Team01\\lib\\site-packages\\xgboost\\core.py:1918\u001B[0m, in \u001B[0;36mBooster.update\u001B[1;34m(self, dtrain, iteration, fobj)\u001B[0m\n\u001B[0;32m   1915\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_dmatrix_features(dtrain)\n\u001B[0;32m   1917\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fobj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1918\u001B[0m     _check_call(\u001B[43m_LIB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mXGBoosterUpdateOneIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1919\u001B[0m \u001B[43m                                            \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mc_int\u001B[49m\u001B[43m(\u001B[49m\u001B[43miteration\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1920\u001B[0m \u001B[43m                                            \u001B[49m\u001B[43mdtrain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1921\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1922\u001B[0m     pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(dtrain, output_margin\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-07-02T18:13:48.783360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the parameter xgb_random\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'subsample': [0.5, 0.7, 1.0],\n",
    "    'colsample_bytree': [0.4, 0.7, 1.0]\n",
    "}\n",
    "\n",
    "print('Check 1')\n",
    "\n",
    "# create model\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "print('check 2')\n",
    "\n",
    "# Create randomised Search object\n",
    "xgb_random = RandomizedSearchCV(xgb_model, param_grid,n_iter= 50, cv=5, scoring='r2', random_state=42)\n",
    "print('check 3')\n",
    "\n",
    "# Fit the xgb_random search object to the data\n",
    "xgb_random.fit(X_train, y_train)\n",
    "print('check 4')\n",
    "\n",
    "# Print the best parameters and the corresponding score\n",
    "print(xgb_random.best_params_)\n",
    "print(xgb_random.best_score_)\n",
    "print(\"check 5\")\n",
    "\n",
    "# Get the best model\n",
    "xgb_random_best_model = xgb_random.best_estimator_\n",
    "\n",
    "# Calculate feature importance\n",
    "importance_scores = xgb_random_best_model.feature_importances_\n",
    "print(\"check 6\")\n",
    "\n",
    "# Create a dataframe for feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importance_scores\n",
    "})\n",
    "print(\"check 7\")\n",
    "\n",
    "# Sort the dataframe by importance\n",
    "importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "print(\"check 8\")\n",
    "\n",
    "# Plot the feature importance\n",
    "importance_df.plot(kind='bar', x='Feature', y='Importance', title='Feature Importance', figsize=(15, 6))\n",
    "plt.ylabel('Importance Score')\n",
    "plt.show()"
   ],
   "id": "666259743333da84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check 1\n",
      "check 2\n",
      "check 3\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_pred_tree = tree_grid.best_estimator_.predict(X_val)\n",
    "y_pred_lgbm = lgbm_grid.best_estimator_.predict(X_val)\n",
    "y_pred_xgb = xgb_grid.best_estimator_.predict(X_val)\n",
    "\n",
    "mse_tree = mean_squared_error(y_val, y_pred_tree)\n",
    "mae_tree = mean_absolute_error(y_val, y_pred_tree)\n",
    "r2_tree = r2_score(y_val, y_pred_tree)\n",
    "mse_lgbm = mean_squared_error(y_val, y_pred_lgbm)\n",
    "mae_lgbm = mean_absolute_error(y_val, y_pred_lgbm)\n",
    "r2_lgbm = r2_score(y_val, y_pred_lgbm)\n",
    "mse_xgb = mean_squared_error(y_val, y_pred_xgb)\n",
    "mae_xgb = mean_absolute_error(y_val, y_pred_xgb)\n",
    "r2_xgb = r2_score(y_val, y_pred_xgb)\n",
    "\n",
    "models = ['Decision Tree', 'LightGBM', 'XGBoost']\n",
    "mse_values = [mse_tree, mse_lgbm, mse_xgb]\n",
    "mae_values = [mae_tree, mae_lgbm, mae_xgb]\n",
    "r2_values = [r2_tree, r2_lgbm, r2_xgb]\n",
    "\n",
    "# Function to print the values\n",
    "def print_values(values, models, title):\n",
    "    print(title)\n",
    "    for model, value in zip(models, values):\n",
    "        print(f\"{model}: {value}\")\n",
    "\n",
    "# Function to plot the values\n",
    "def plot_values(values, title, models, ylabel):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    sns.barplot(x=models, y=values)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "\n",
    "# Print and plot MSE values\n",
    "print_values(mse_values, models, 'Comparison of Mean Squared Error')\n",
    "print_values(r2_values, models, 'Comparison of R2 Score')\n",
    "print_values(mae_values, models, 'Comparison of Mean Absolute Error')\n",
    "plot_values(mse_values, 'Comparison of Mean Squared Error', models, 'MSE')\n",
    "\n",
    "# Print and plot MAE values\n",
    "\n",
    "plot_values(mae_values, 'Comparison of Mean Absolute Error', models, 'MAE')\n",
    "\n",
    "# Print and plot R2 values\n",
    "\n",
    "plot_values(r2_values, 'Comparison of R2 Score', models, 'R2 Score')"
   ],
   "id": "d83524c15b94ea6c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
